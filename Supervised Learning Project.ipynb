{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R88Ms0MTi0Ma"
   },
   "source": [
    "# User Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WA6lL1fni0Mb"
   },
   "source": [
    "**In** this project, we use supervised learning models to identify customers who are likely to stop using service in the future. Furthermore, we will analyze top factors that influence user retention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bO94-bXZi0Md"
   },
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SIvRSRqAi0Md"
   },
   "source": [
    "<ul>\n",
    "<li>[Part 1: Data Exploration](#Part-1:-Data-Exploration)\n",
    "<li>[Part 2: Feature Preprocessing](#Part-2:-Feature-Preprocessing)\n",
    "<li>[Part 3: Model Training and Results Evaluation](#Part-3:-Model-Training-and-Result-Evaluation)\n",
    "<li>[Part 4: Feature Selection](#Part-4:-Feature-Selection)\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TUoI2S7Bi6iR"
   },
   "source": [
    "# Part 0: Setup Google Drive Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "neechzbWi7rV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "WARNING: You are using pip version 20.3.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-23adbfa94fa6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrive\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGoogleDrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# method 1 install pydrive to load data\n",
    "!pip install -U -q PyDrive\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UScKyL2TjARW"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'drive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-50109e992ad1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://drive.google.com/open?id=1BmXe8XIPvbghz7kMEjmt9vBX8LZbX4Jq'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfluff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'='\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# replace the id with id of file you want to access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetContentFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'churn.all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'drive' is not defined"
     ]
    }
   ],
   "source": [
    "link = 'https://drive.google.com/open?id=1BmXe8XIPvbghz7kMEjmt9vBX8LZbX4Jq'\n",
    "fluff, id = link.split('=')\n",
    "file = drive.CreateFile({'id':id}) # replace the id with id of file you want to access\n",
    "file.GetContentFile('churn.all')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nK7A1qhYSDxM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('churn.all')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vhMVchpMPjRc"
   },
   "outputs": [],
   "source": [
    "# method 2 upload from local\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M31NVxpbPvS9"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "df2 = pd.read_csv(io.BytesIO(uploaded['uk_rain_2014.csv']))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ikYHWOnYfKPM"
   },
   "source": [
    "**Homework 0: Use the recommended way to load data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "1iLCfrlpe-pV"
   },
   "outputs": [],
   "source": [
    "#@title Homework 0\n",
    "####\n",
    "## Your Code\n",
    "####\n",
    "#import pandas as pd\n",
    "#file_id='1BmXe8XIPvbghz7kMEjmt9vBX8LZbX4Jq'\n",
    "#link='https://drive.google.com/uc?export=download&id={FILE_ID}'\n",
    "#csv_url=link.format(FILE_ID=file_id)\n",
    "#my_data = pd.read_csv(csv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KbCamNSoLcuX"
   },
   "outputs": [],
   "source": [
    "my_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6bG_gAPi0Me"
   },
   "source": [
    "# Part 1: Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bspx2K6fi0Me"
   },
   "source": [
    "### Part 1.1: Understand the Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kuTHKjk-i0Mf"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4c9d3fba3e99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# will show all the columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_columns'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imblearn\n",
    "# will show all the columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "churn_df = pd.read_csv('churn.all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "CtUqK6j1fhDN"
   },
   "outputs": [],
   "source": [
    "#@title *Bonus (不需要掌握): The Iris dataset in sklearn*\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "print(type(iris)) # bunch like dictionary\n",
    "print(iris.keys())\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hHNZRs2Ti0Mi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "churn_df.head()\n",
    "# churn_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C99Z9b7ai0Mm"
   },
   "outputs": [],
   "source": [
    "print (\"Num of rows: \" + str(churn_df.shape[0])) # row count\n",
    "print (\"Num of columns: \" + str(churn_df.shape[1])) # col count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OCglmJ9Oi0Mo"
   },
   "source": [
    "### Part 1.2: Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxlrXRG3i0Mp"
   },
   "source": [
    "Remove Extra Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Vf8iYmWi0Mq",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'churn_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8c5fde74b7f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# check categorical feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mchurn_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'voice_mail_plan'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'churn_df' is not defined"
     ]
    }
   ],
   "source": [
    "# check categorical feature\n",
    "churn_df['voice_mail_plan'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3lpwxvQfi0Mt"
   },
   "outputs": [],
   "source": [
    "# remove the heading and trailing whitespaces\n",
    "churn_df['voice_mail_plan'] = churn_df['voice_mail_plan'].map(lambda x: x.strip())\n",
    "churn_df['intl_plan'] = churn_df['intl_plan'].map(lambda x: x.strip())\n",
    "churn_df['churned'] = churn_df['churned'].map(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kcyHhHKHZN2p"
   },
   "outputs": [],
   "source": [
    "# check the categorical feature after manipulation\n",
    "churn_df['voice_mail_plan'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsAbAjhvi0Mx"
   },
   "source": [
    "### Part 1.3:  Understand the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rJ0AdxwLi0Mz",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check the feature distribution\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(churn_df['total_intl_charge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DKTTdB6i0M2"
   },
   "outputs": [],
   "source": [
    "# correlations between all the features\n",
    "corr = churn_df[[\"account_length\", \"number_vmail_messages\", \"total_day_minutes\",\n",
    "                    \"total_day_calls\", \"total_day_charge\", \"total_eve_minutes\",\n",
    "                    \"total_eve_calls\", \"total_eve_charge\", \"total_night_minutes\",\n",
    "                    \"total_night_calls\", \"total_intl_minutes\", \"total_intl_calls\",\n",
    "                    \"total_intl_charge\"]].corr()\n",
    "\n",
    "# show heapmap of correlations\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1qfEnNW_i0M5"
   },
   "outputs": [],
   "source": [
    "# check the actual values of correlations\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aFa4d6t3i0NH"
   },
   "source": [
    "# Part 2: Feature Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wtjI61m6i0M8"
   },
   "outputs": [],
   "source": [
    "# calculate two features correlation\n",
    "from scipy.stats import pearsonr\n",
    "print (pearsonr(churn_df['total_day_minutes'], churn_df['number_vmail_messages'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pxtf6XoJi0NI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ec5r_Qdi0NL"
   },
   "outputs": [],
   "source": [
    "# Get ground truth data\n",
    "y = np.where(churn_df['churned'] == 'True.',1,0)\n",
    "\n",
    "# Drop some useless columns\n",
    "to_drop = ['state','area_code','phone_number','churned']\n",
    "churn_feat_space = churn_df.drop(to_drop, axis=1)\n",
    "\n",
    "# yes and no have to be converted to boolean values\n",
    "yes_no_cols = [\"intl_plan\",\"voice_mail_plan\"]\n",
    "churn_feat_space[yes_no_cols] = churn_feat_space[yes_no_cols] == 'yes'\n",
    "\n",
    "X = churn_feat_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7cWYAEiNJj_T"
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzCo_GC97rGd"
   },
   "outputs": [],
   "source": [
    "# check the propotion of y = 1\n",
    "print(y.sum() / y.shape * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oNsZwmWxi0NP"
   },
   "source": [
    "#### Homework 1: Can you add catogorical features, e.g. state, into your feature matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JMTIEpY7IfPp"
   },
   "source": [
    "Read more for handling [categorical feature](https://github.com/scikit-learn-contrib/categorical-encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "MrsjiqTwi0NQ"
   },
   "outputs": [],
   "source": [
    "#@title Homework 1\n",
    "####\n",
    "## Your Code\n",
    "####\n",
    "\n",
    "#to_drop_hw1 = ['area_code','phone_number','churned']\n",
    "#churn_feat_space_hw1 = churn_df.drop(to_drop_hw1, axis=1)\n",
    "\n",
    "# yes and no have to be converted to boolean values\n",
    "#yes_no_cols = [\"intl_plan\",\"voice_mail_plan\"]\n",
    "#churn_feat_space_hw1[yes_no_cols] = churn_feat_space_hw1[yes_no_cols] == 'yes'\n",
    "\n",
    "#churn_feat_space_hw1 = pd.get_dummies(churn_feat_space_hw1, columns=['state'])\n",
    "\n",
    "#churn_feat_space_hw1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q3x9ySX_i0Nd"
   },
   "source": [
    "# Part 3: Model Training and Result Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77OjmSl9i0Nf"
   },
   "source": [
    "### Part 3.1: Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uay8Md5li0Nh"
   },
   "outputs": [],
   "source": [
    "# Splite data into training and testing\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Reserve 20% for testing\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print('training data has %d observation with %d features'% X_train.shape)\n",
    "print('test data has %d observation with %d features'% X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JuPhtUkJi0NW"
   },
   "outputs": [],
   "source": [
    "# Scale the data, using standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4UTtCQTi0Nl"
   },
   "source": [
    "### Part 3.2: Model Training and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "EAhSxINLi0Nl"
   },
   "outputs": [],
   "source": [
    "#@title build models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression\n",
    "classifier_logistic = LogisticRegression()\n",
    "\n",
    "# K Nearest Neighbors\n",
    "classifier_KNN = KNeighborsClassifier()\n",
    "\n",
    "# Random Forest\n",
    "classifier_RF = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Av0IRSoBQ3pe"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "classifier_logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EiLuzUDJRBNi"
   },
   "outputs": [],
   "source": [
    "# Prediction of test data\n",
    "classifier_logistic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XjMV04mKRJ30"
   },
   "outputs": [],
   "source": [
    "# Accuracy of test data\n",
    "classifier_logistic.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1OCgNSNri0Nn"
   },
   "outputs": [],
   "source": [
    "# Use 5-fold Cross Validation to get the accuracy for different models\n",
    "model_names = ['Logistic Regression','KNN','Random Forest']\n",
    "model_list = [classifier_logistic, classifier_KNN, classifier_RF]\n",
    "count = 0\n",
    "\n",
    "for classifier in model_list:\n",
    "    cv_score = model_selection.cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "    # cprint(cv_score)\n",
    "    print('Model accuracy of %s is: %.3f'%(model_names[count],cv_score.mean()))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G1GCzaPxi0Np"
   },
   "source": [
    "#### Homework 2: Can you do prediction with SVM model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "yxmKTdahi0Nq"
   },
   "outputs": [],
   "source": [
    "#@title Homework 2\n",
    "####\n",
    "## Your Code\n",
    "####\n",
    "# SVC\n",
    "#from sklearn.svm import SVC \n",
    "\n",
    "#classifier_SVC = SVC()\n",
    "\n",
    "#cv_score = model_selection.cross_val_score(classifier_SVC, X_train, y_train, cv=5)\n",
    "#print('Model accuracy of SVM is: %.3f'%(cv_score.mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7J-23z78i0Ns"
   },
   "source": [
    "### (Optional) Part 3.3: Use Grid Search to Find Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hpe9PEAAi0Nt"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# helper function for printing out grid search results \n",
    "def print_grid_search_metrics(gs):\n",
    "    print (\"Best score: %0.3f\" % gs.best_score_)\n",
    "    print (\"Best parameters set:\")\n",
    "    best_parameters = gs.best_params_\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qvYo9I5Ti0Nv"
   },
   "source": [
    "#### Part 3.3.1: Find Optimal Hyperparameters - LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wOc48syxi0Nx",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Possible hyperparamter options for Logistic Regression Regularization\n",
    "# Penalty is choosed from L1 or L2\n",
    "# C is the lambda value(weight) for L1 and L2\n",
    "parameters = {\n",
    "    'penalty':('l1', 'l2'), \n",
    "    'C':(1, 5, 10)\n",
    "}\n",
    "Grid_LR = GridSearchCV(LogisticRegression(),parameters, cv=5)\n",
    "Grid_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nN5rU0e-i0N1"
   },
   "outputs": [],
   "source": [
    "# the best hyperparameter combination\n",
    "print_grid_search_metrics(Grid_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtkDsXgui0N3"
   },
   "outputs": [],
   "source": [
    "# best model\n",
    "best_LR_model = Grid_LR.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9u9YFedOi0N6"
   },
   "source": [
    "#### Part 3.3.2: Find Optimal Hyperparameters: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o78422XVi0N6"
   },
   "outputs": [],
   "source": [
    "# Possible hyperparamter options for KNN\n",
    "# Choose k\n",
    "parameters = {\n",
    "    'n_neighbors':[3,5,7,10] \n",
    "}\n",
    "Grid_KNN = GridSearchCV(KNeighborsClassifier(),parameters, cv=5)\n",
    "Grid_KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ydaRZVAIi0N_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# best k\n",
    "print_grid_search_metrics(Grid_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKn_oKLSi0OB"
   },
   "source": [
    "#### Part 3.3.3: Find Optimal Hyperparameters: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NniAZIPfi0OC"
   },
   "outputs": [],
   "source": [
    "# Possible hyperparamter options for Random Forest\n",
    "# Choose the number of trees\n",
    "parameters = {\n",
    "    'n_estimators' : [40,60,80]\n",
    "}\n",
    "Grid_RF = GridSearchCV(RandomForestClassifier(),parameters, cv=5)\n",
    "Grid_RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScPiI-Bfi0OE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# best number of tress\n",
    "print_grid_search_metrics(Grid_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xJgfri_Mi0OG"
   },
   "outputs": [],
   "source": [
    "# best random forest\n",
    "best_RF_model = Grid_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xxDAOrGIi0OI"
   },
   "source": [
    "### Part 3.4: Model Evaluation - Confusion Matrix (Precision, Recall, Accuracy)\n",
    "\n",
    "class of interest as positive\n",
    "\n",
    "TP: correctly labeled real churn\n",
    "\n",
    "Precision(PPV, positive predictive value): tp / (tp + fp);\n",
    "Total number of true predictive churn divided by the total number of predictive churn;\n",
    "High Precision means low fp, not many return users were predicted as churn users. \n",
    "\n",
    "\n",
    "Recall(sensitivity, hit rate, true positive rate): tp / (tp + fn)\n",
    "Predict most postive or churn user correctly. High recall means low fn, not many churn users were predicted as return users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-tP94iFi0OI"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# calculate accuracy, precision and recall\n",
    "def cal_evaluation(classifier, cm):\n",
    "    tn = cm[0][0]\n",
    "    fp = cm[0][1]\n",
    "    fn = cm[1][0]\n",
    "    tp = cm[1][1]\n",
    "    accuracy  = (tp + tn) / (tp + fp + fn + tn + 0.0)\n",
    "    precision = tp / (tp + fp + 0.0)\n",
    "    recall = tp / (tp + fn + 0.0)\n",
    "    print (classifier)\n",
    "    print (\"Accuracy is: %0.3f\" % accuracy)\n",
    "    print (\"precision is: %0.3f\" % precision)\n",
    "    print (\"recall is: %0.3f\" % recall)\n",
    "\n",
    "# print out confusion matrices\n",
    "def draw_confusion_matrices(confusion_matricies):\n",
    "    class_names = ['Not','Churn']\n",
    "    for cm in confusion_matrices:\n",
    "        classifier, cm = cm[0], cm[1]\n",
    "        cal_evaluation(classifier, cm)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        cax = ax.matshow(cm, interpolation='nearest',cmap=plt.get_cmap('Reds'))\n",
    "        plt.title('Confusion matrix for %s' % classifier)\n",
    "        fig.colorbar(cax)\n",
    "        ax.set_xticklabels([''] + class_names)\n",
    "        ax.set_yticklabels([''] + class_names)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OpSGaN49i0OL"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Confusion matrix, accuracy, precison and recall for random forest and logistic regression\n",
    "confusion_matrices = [\n",
    "    (\"Random Forest\", confusion_matrix(y_test,best_RF_model.predict(X_test))),\n",
    "    (\"Logistic Regression\", confusion_matrix(y_test,best_LR_model.predict(X_test))),\n",
    "]\n",
    "\n",
    "draw_confusion_matrices(confusion_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OvHlyhPBi0OT"
   },
   "source": [
    "### Part 3.4: Model Evaluation - ROC & AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jx_3XkgKi0OW"
   },
   "source": [
    "RandomForestClassifier, KNeighborsClassifier and LogisticRegression have predict_prob() function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Os_ZLTvi0OX"
   },
   "source": [
    "#### Part 3.4.1: ROC of RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UypvQMVBi0OY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "# Use predict_proba to get the probability results of Random Forest\n",
    "y_pred_rf = best_RF_model.predict_proba(X_test)[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3PR-PdPi0Ob"
   },
   "outputs": [],
   "source": [
    "# ROC curve of Random Forest result\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve - RF model')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R89IUMYDi0Oe"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# AUC score\n",
    "metrics.auc(fpr_rf,tpr_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-1DVqnJVi0Oh"
   },
   "source": [
    "#### Part 3.4.1: ROC of LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-q5XJPoi0Oi"
   },
   "outputs": [],
   "source": [
    "# Use predict_proba to get the probability results of Logistic Regression\n",
    "y_pred_lr = best_LR_model.predict_proba(X_test)[:, 1]\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZSrN-1Mi0Ok"
   },
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_lr, tpr_lr, label='LR')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve - LR Model')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHAyxishi0On"
   },
   "outputs": [],
   "source": [
    "# AUC score\n",
    "metrics.auc(fpr_lr,tpr_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gHHurD8Ii0Oq"
   },
   "source": [
    "# Part 4: Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSx4TPO-i0Or"
   },
   "source": [
    "### Part 4.1:  Logistic Regression Model - Feature Selection Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BtLHUixoi0Ot"
   },
   "source": [
    "The corelated features that we are interested in: (total_day_minutes, total_day_charge), (total_eve_minutes, total_eve_charge), (total_intl_minutes, total_intl_charge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cQaXOIsUi0Ou",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add L1 regularization to logistic regression\n",
    "# check the coef for feature selection\n",
    "scaler = StandardScaler()\n",
    "X_l1 = scaler.fit_transform(X)\n",
    "LRmodel_l1 = LogisticRegression(penalty=\"l1\", C = 0.1)\n",
    "LRmodel_l1.fit(X_l1, y)\n",
    "LRmodel_l1.coef_[0]\n",
    "print (\"Logistic Regression (L1) Coefficients\")\n",
    "for k,v in sorted(zip(map(lambda x: round(x, 4), LRmodel_l1.coef_[0]), \\\n",
    "                      churn_feat_space.columns), key=lambda k_v:(-abs(k_v[0]),k_v[1])):\n",
    "    print (v + \": \" + str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "majifZZqi0O9"
   },
   "outputs": [],
   "source": [
    "# add L2 regularization to logistic regression\n",
    "# check the coef for feature selection\n",
    "scaler = StandardScaler()\n",
    "X_l2 = scaler.fit_transform(X)\n",
    "LRmodel_l2 = LogisticRegression(penalty=\"l2\", C = 5)\n",
    "LRmodel_l2.fit(X_l2, y)\n",
    "LRmodel_l2.coef_[0]\n",
    "print (\"Logistic Regression (L2) Coefficients\")\n",
    "for k,v in sorted(zip(map(lambda x: round(x, 4), LRmodel_l2.coef_[0]), \\\n",
    "                      churn_feat_space.columns), key=lambda k_v:(-abs(k_v[0]),k_v[1])):\n",
    "    print (v + \": \" + str(k))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uqs41ydLi0O_"
   },
   "source": [
    "### Part 4.2:  Random Forest Model - Feature Importance Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPxUM2lei0PA"
   },
   "outputs": [],
   "source": [
    "# check feature importance of random forest for feature selection\n",
    "forest = RandomForestClassifier()\n",
    "forest.fit(X, y)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature importance ranking by Random Forest Model:\")\n",
    "for k,v in sorted(zip(map(lambda x: round(x, 4), importances), churn_feat_space.columns), reverse=True):\n",
    "    print (v + \": \" + str(k))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Supervised Learning Project.ipynb",
   "provenance": [
    {
     "file_id": "1BtyDGHRJSmlyi29CPUH8ZNmzh-j0eg3d",
     "timestamp": 1545526424684
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
